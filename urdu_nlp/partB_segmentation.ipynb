{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86e5c913",
   "metadata": {},
   "source": [
    "# Part B: Sentence Segmentation in Urdu\n",
    "\n",
    "## Approach\n",
    "Urdu sentence segmentation is challenging because:\n",
    "- Urdu uses its own punctuation (e.g., `۔` full stop, `؟` question mark, `!` exclamation)\n",
    "- Spaces may be omitted between words (Space Omission Problem)\n",
    "- Extra spaces may be inserted inside words (Space Insertion Problem)\n",
    "- Multiple sentences are often run together without proper delimiters in noisy corpora\n",
    "\n",
    "**Strategy:**\n",
    "1. Normalize whitespace (fix Space Insertion Problem)\n",
    "2. Identify sentence boundaries using Urdu punctuation markers (`۔`, `؟`, `!`, `؟`) and contextual end-word cues\n",
    "3. Split on detected boundaries\n",
    "4. Evaluate using Precision, Recall, and F1-score against a manually annotated gold standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d92f95d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part B functions defined successfully.\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Part B: Urdu Sentence Segmentation\n",
    "# ============================================================\n",
    "\n",
    "import re\n",
    "from typing import List, Tuple\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# Step 1: Text Normalization\n",
    "# Fix Space Insertion Problem: remove spurious spaces inside Urdu words\n",
    "# Fix Space Omission Problem: ensure space after sentence-ending punctuation\n",
    "# ---------------------------------------------------------------\n",
    "\n",
    "# Common Urdu sentence-ending words (end-of-sentence cues)\n",
    "# These are common Urdu words that typically appear at the end of a sentence\n",
    "URDU_SENTENCE_FINAL_WORDS = [\n",
    "    'ہے', 'ہیں', 'تھا', 'تھی', 'تھے', 'گا', 'گی', 'گے',\n",
    "    'دیا', 'لیا', 'کیا', 'آیا', 'گیا', 'ہوا', 'ہوئی', 'ہوئے',\n",
    "    'چاہیے', 'سکتا', 'سکتی', 'سکتے', 'چاہتا', 'چاہتی',\n",
    "    'پہنچا', 'پہنچی', 'نہیں', 'ملا', 'ملی', 'رہا', 'رہی', 'رہے'\n",
    "]\n",
    "\n",
    "# Urdu punctuation that marks sentence end\n",
    "URDU_END_PUNCT = r'[۔؟!]'\n",
    "\n",
    "\n",
    "def normalize_whitespace(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Fix Space Insertion Problem:\n",
    "    Collapse multiple consecutive spaces into a single space.\n",
    "    Also strip leading/trailing whitespace from the full text.\n",
    "    \"\"\"\n",
    "    # Replace multiple spaces/tabs with a single space\n",
    "    text = re.sub(r'[ \\t]+', ' ', text)\n",
    "    # Normalize newlines\n",
    "    text = re.sub(r'\\n+', '\\n', text)\n",
    "    return text.strip()\n",
    "\n",
    "\n",
    "def ensure_space_after_punct(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Ensure there is at least one space after Urdu sentence-ending punctuation\n",
    "    (helps with Space Omission Problem at sentence boundaries).\n",
    "    \"\"\"\n",
    "    # Add space after ۔ ؟ ! if not followed by space or newline\n",
    "    text = re.sub(r'([۔؟!])([^\\s])', r'\\1 \\2', text)\n",
    "    return text\n",
    "\n",
    "\n",
    "def preprocess(text: str) -> str:\n",
    "    \"\"\"Full preprocessing pipeline.\"\"\"\n",
    "    text = normalize_whitespace(text)\n",
    "    text = ensure_space_after_punct(text)\n",
    "    return text\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# Step 2: Sentence Segmentation\n",
    "# ---------------------------------------------------------------\n",
    "\n",
    "def segment_sentences(text: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Segment Urdu text into individual sentences.\n",
    "\n",
    "    Strategy:\n",
    "    1. Preprocess (normalize whitespace, ensure space after punctuation)\n",
    "    2. Split on Urdu sentence-ending punctuation (۔ ؟ !)\n",
    "    3. Apply end-word heuristic: if a token matches a known sentence-final\n",
    "       word and the next token starts a new potential sentence (starts with\n",
    "       a capital letter equivalent or a recognized sentence-starting pattern),\n",
    "       insert a boundary.\n",
    "    4. Clean up empty segments.\n",
    "    \"\"\"\n",
    "    text = preprocess(text)\n",
    "\n",
    "    # Primary split: on Urdu end punctuation, keeping the punctuation\n",
    "    # Use a lookahead to split AFTER the punctuation character\n",
    "    raw_segments = re.split(r'(?<=[۔؟!])\\s*', text)\n",
    "\n",
    "    sentences = []\n",
    "    buffer = ''\n",
    "\n",
    "    for seg in raw_segments:\n",
    "        seg = seg.strip()\n",
    "        if not seg:\n",
    "            continue\n",
    "\n",
    "        # Check if this segment already ends with Urdu punctuation\n",
    "        if re.search(URDU_END_PUNCT + r'$', seg):\n",
    "            if buffer:\n",
    "                sentences.append((buffer + ' ' + seg).strip())\n",
    "                buffer = ''\n",
    "            else:\n",
    "                sentences.append(seg)\n",
    "        else:\n",
    "            # No ending punctuation: apply end-word heuristic\n",
    "            words = seg.split()\n",
    "            sub_sentence = []\n",
    "            for i, word in enumerate(words):\n",
    "                sub_sentence.append(word)\n",
    "                # If word matches a sentence-final cue and there are more words\n",
    "                if word in URDU_SENTENCE_FINAL_WORDS and i < len(words) - 1:\n",
    "                    candidate = ' '.join(sub_sentence).strip()\n",
    "                    if buffer:\n",
    "                        sentences.append((buffer + ' ' + candidate).strip())\n",
    "                        buffer = ''\n",
    "                    else:\n",
    "                        sentences.append(candidate)\n",
    "                    sub_sentence = []\n",
    "            # Remaining words go to buffer\n",
    "            remainder = ' '.join(sub_sentence).strip()\n",
    "            if remainder:\n",
    "                buffer = (buffer + ' ' + remainder).strip() if buffer else remainder\n",
    "\n",
    "    # Flush remaining buffer\n",
    "    if buffer:\n",
    "        sentences.append(buffer)\n",
    "\n",
    "    # Final cleanup: remove empty strings and strip whitespace\n",
    "    sentences = [s.strip() for s in sentences if s.strip()]\n",
    "    return sentences\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# Step 3: Evaluation Function\n",
    "# ---------------------------------------------------------------\n",
    "\n",
    "def evaluate_segmentation(\n",
    "    predicted: List[str],\n",
    "    gold: List[str]\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Evaluate sentence segmentation using boundary-based Precision, Recall, F1.\n",
    "\n",
    "    Method:\n",
    "    - Reconstruct the original text from both predicted and gold sentence lists.\n",
    "    - Identify boundary positions (character offsets where each sentence ends)\n",
    "      in the original text.\n",
    "    - Compare predicted boundaries to gold boundaries.\n",
    "\n",
    "    Returns:\n",
    "        dict with keys: precision, recall, f1, correct, predicted_count, gold_count\n",
    "    \"\"\"\n",
    "    def get_boundaries(sentences: List[str]) -> set:\n",
    "        \"\"\"Return set of cumulative character offsets at each sentence boundary.\"\"\"\n",
    "        boundaries = set()\n",
    "        offset = 0\n",
    "        for i, sent in enumerate(sentences[:-1]):  # no boundary after last sentence\n",
    "            offset += len(sent)\n",
    "            boundaries.add(offset)\n",
    "            offset += 1  # account for space between sentences\n",
    "        return boundaries\n",
    "\n",
    "    pred_boundaries = get_boundaries(predicted)\n",
    "    gold_boundaries = get_boundaries(gold)\n",
    "\n",
    "    # Allow a small tolerance window (±2 chars) for boundary matching\n",
    "    TOLERANCE = 2\n",
    "\n",
    "    correct = 0\n",
    "    matched_gold = set()\n",
    "    for pb in pred_boundaries:\n",
    "        for gb in gold_boundaries:\n",
    "            if abs(pb - gb) <= TOLERANCE and gb not in matched_gold:\n",
    "                correct += 1\n",
    "                matched_gold.add(gb)\n",
    "                break\n",
    "\n",
    "    precision = correct / len(pred_boundaries) if pred_boundaries else 0.0\n",
    "    recall = correct / len(gold_boundaries) if gold_boundaries else 0.0\n",
    "    f1 = (2 * precision * recall / (precision + recall)) if (precision + recall) > 0 else 0.0\n",
    "\n",
    "    return {\n",
    "        'precision': round(precision, 4),\n",
    "        'recall': round(recall, 4),\n",
    "        'f1': round(f1, 4),\n",
    "        'correct_boundaries': correct,\n",
    "        'predicted_boundaries': len(pred_boundaries),\n",
    "        'gold_boundaries': len(gold_boundaries)\n",
    "    }\n",
    "\n",
    "\n",
    "print(\"Part B functions defined successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f33cf10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TEST 1: Assignment sample text\n",
      "============================================================\n",
      "INPUT:\n",
      " بے چاری عوام چونکہ ہمیشہ سے دھوکہ کھانے کی عادی رہی ہے اس لئے تبدیل سرکار کی چکنی چپڑی باتوں میں آگئی اور اپنے بہتر مستقبل کے لئے نئی حکومت کو اقتدار کے ایوانوں تک پہنچا دیا۔\n",
      "\n",
      "SEGMENTED (1 sentence(s)):\n",
      "  [1] بے چاری عوام چونکہ ہمیشہ سے دھوکہ کھانے کی عادی رہی ہے اس لئے تبدیل سرکار کی چکنی چپڑی باتوں میں آگئی اور اپنے بہتر مستقبل کے لئے نئی حکومت کو اقتدار کے ایوانوں تک پہنچا دیا۔\n",
      "\n",
      "============================================================\n",
      "TEST 2: Multi-sentence Urdu corpus\n",
      "============================================================\n",
      "INPUT:\n",
      " پاکستان ایک خوبصورت ملک ہے۔ اس کی آبادی بیس کروڑ سے زیادہ ہے۔ اسلام آباد پاکستان کا دارالحکومت ہے۔ یہاں بہت سے تاریخی مقامات موجود ہیں۔ کیا آپ کبھی پاکستان گئے ہیں؟ پاکستانی کھانا بہت لذیذ ہوتا ہے!\n",
      "\n",
      "SEGMENTED (6 sentence(s)):\n",
      "  [1] پاکستان ایک خوبصورت ملک ہے۔\n",
      "  [2] اس کی آبادی بیس کروڑ سے زیادہ ہے۔\n",
      "  [3] اسلام آباد پاکستان کا دارالحکومت ہے۔\n",
      "  [4] یہاں بہت سے تاریخی مقامات موجود ہیں۔\n",
      "  [5] کیا آپ کبھی پاکستان گئے ہیں؟\n",
      "  [6] پاکستانی کھانا بہت لذیذ ہوتا ہے!\n",
      "\n",
      "============================================================\n",
      "TEST 3: Space insertion problem text\n",
      "============================================================\n",
      "INPUT:\n",
      " پاکستان  ایک   خوبصورت   ملک  ہے۔  اس   کی  آبادی  بہت  زیادہ   ہے۔\n",
      "\n",
      "SEGMENTED (2 sentence(s)):\n",
      "  [1] پاکستان ایک خوبصورت ملک ہے۔\n",
      "  [2] اس کی آبادی بہت زیادہ ہے۔\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------------\n",
    "# Test on sample Urdu text (from the assignment PDF)\n",
    "# ---------------------------------------------------------------\n",
    "\n",
    "# Example from assignment: two Urdu sentences joined together\n",
    "sample_text = (\n",
    "    \"بے چاری عوام چونکہ ہمیشہ سے دھوکہ کھانے کی عادی رہی ہے اس لئے تبدیل سرکار کی چکنی چپڑی باتوں میں آگئی \"\n",
    "    \"اور اپنے بہتر مستقبل کے لئے نئی حکومت کو اقتدار کے ایوانوں تک پہنچا دیا۔\"\n",
    ")\n",
    "\n",
    "# Multi-sentence Urdu test corpus\n",
    "multi_sentence_text = (\n",
    "    \"پاکستان ایک خوبصورت ملک ہے۔ اس کی آبادی بیس کروڑ سے زیادہ ہے۔ \"\n",
    "    \"اسلام آباد پاکستان کا دارالحکومت ہے۔ یہاں بہت سے تاریخی مقامات موجود ہیں۔ \"\n",
    "    \"کیا آپ کبھی پاکستان گئے ہیں؟ پاکستانی کھانا بہت لذیذ ہوتا ہے!\"\n",
    ")\n",
    "\n",
    "# Text with space insertion problem\n",
    "space_insertion_text = (\n",
    "    \"پاکستان  ایک   خوبصورت   ملک  ہے۔  اس   کی  آبادی  بہت  زیادہ   ہے۔\"\n",
    ")\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"TEST 1: Assignment sample text\")\n",
    "print(\"=\" * 60)\n",
    "print(\"INPUT:\\n\", sample_text)\n",
    "segs = segment_sentences(sample_text)\n",
    "print(f\"\\nSEGMENTED ({len(segs)} sentence(s)):\")\n",
    "for i, s in enumerate(segs, 1):\n",
    "    print(f\"  [{i}] {s}\")\n",
    "\n",
    "print()\n",
    "print(\"=\" * 60)\n",
    "print(\"TEST 2: Multi-sentence Urdu corpus\")\n",
    "print(\"=\" * 60)\n",
    "print(\"INPUT:\\n\", multi_sentence_text)\n",
    "segs2 = segment_sentences(multi_sentence_text)\n",
    "print(f\"\\nSEGMENTED ({len(segs2)} sentence(s)):\")\n",
    "for i, s in enumerate(segs2, 1):\n",
    "    print(f\"  [{i}] {s}\")\n",
    "\n",
    "print()\n",
    "print(\"=\" * 60)\n",
    "print(\"TEST 3: Space insertion problem text\")\n",
    "print(\"=\" * 60)\n",
    "print(\"INPUT:\\n\", space_insertion_text)\n",
    "segs3 = segment_sentences(space_insertion_text)\n",
    "print(f\"\\nSEGMENTED ({len(segs3)} sentence(s)):\")\n",
    "for i, s in enumerate(segs3, 1):\n",
    "    print(f\"  [{i}] {s}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d4941a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "EVALUATION RESULTS\n",
      "============================================================\n",
      "Gold boundaries       : 5\n",
      "Predicted boundaries  : 5\n",
      "Correctly matched     : 5\n",
      "Precision             : 1.0000\n",
      "Recall                : 1.0000\n",
      "F1 Score              : 1.0000\n",
      "\n",
      "Predicted sentences:\n",
      "  [1] پاکستان ایک خوبصورت ملک ہے۔\n",
      "  [2] اس کی آبادی بیس کروڑ سے زیادہ ہے۔\n",
      "  [3] اسلام آباد پاکستان کا دارالحکومت ہے۔\n",
      "  [4] یہاں بہت سے تاریخی مقامات موجود ہیں۔\n",
      "  [5] کیا آپ کبھی پاکستان گئے ہیں؟\n",
      "  [6] پاکستانی کھانا بہت لذیذ ہوتا ہے!\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------------\n",
    "# Evaluation Test\n",
    "# ---------------------------------------------------------------\n",
    "\n",
    "# Gold-standard (manually defined expected segmentation)\n",
    "gold_standard = [\n",
    "    \"پاکستان ایک خوبصورت ملک ہے۔\",\n",
    "    \"اس کی آبادی بیس کروڑ سے زیادہ ہے۔\",\n",
    "    \"اسلام آباد پاکستان کا دارالحکومت ہے۔\",\n",
    "    \"یہاں بہت سے تاریخی مقامات موجود ہیں۔\",\n",
    "    \"کیا آپ کبھی پاکستان گئے ہیں؟\",\n",
    "    \"پاکستانی کھانا بہت لذیذ ہوتا ہے!\"\n",
    "]\n",
    "\n",
    "predicted_segmentation = segment_sentences(multi_sentence_text)\n",
    "\n",
    "results = evaluate_segmentation(predicted_segmentation, gold_standard)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"EVALUATION RESULTS\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Gold boundaries       : {results['gold_boundaries']}\")\n",
    "print(f\"Predicted boundaries  : {results['predicted_boundaries']}\")\n",
    "print(f\"Correctly matched     : {results['correct_boundaries']}\")\n",
    "print(f\"Precision             : {results['precision']:.4f}\")\n",
    "print(f\"Recall                : {results['recall']:.4f}\")\n",
    "print(f\"F1 Score              : {results['f1']:.4f}\")\n",
    "\n",
    "print(\"\\nPredicted sentences:\")\n",
    "for i, s in enumerate(predicted_segmentation, 1):\n",
    "    print(f\"  [{i}] {s}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
